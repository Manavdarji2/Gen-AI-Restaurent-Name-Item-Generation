{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f51125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain langchain[google-genai] dotenv langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede552a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2357539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import getpass\n",
    "dotenv.load_dotenv()\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass('GOOGLE_API_KEY') \n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\", temperature=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64619665",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=llm.invoke(\"I want to open a restaurent for Indian Food. Suggest a fency name for this i want only name not preamble and no postamble i want only one name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d4503a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurent for {cuisine} Food. Suggest a fency name for this i want only name not preamble and no postamble i want only one name\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6ff355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurent for Italian Food. Suggest a fency name for this i want only name not preamble and no postamble i want only one name'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_name.format(cuisine=\"Italian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6cbb3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manav Darji\\AppData\\Local\\Temp\\ipykernel_25380\\2094953324.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain=LLMChain(llm=llm, prompt=prompt_template_name)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain=LLMChain(llm=llm, prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f1625d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oro Agave'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Maxican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19f53bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurent for {cuisine} Food. Suggest a fency name for this i want only name not preamble and no postamble i want only one name\"\n",
    ")\n",
    "\n",
    "\n",
    "name_chain=LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "\n",
    "prompt_template_items=PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"\"\"Suggest some Menu item for {restaurant_name}. Return as a commma seperated Value not Preamble and postamble\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82f5cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_item_chain=LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01de0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "\n",
    "\n",
    "chain = SimpleSequentialChain(\n",
    "    chains=[\n",
    "        name_chain,\n",
    "        food_item_chain \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be1affc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gambas al Ajillo Zafiro, Croquetas Cremosas de Jamón Ibérico, Pimientos de Padrón con Sal Marina, Tabla de Quesos Españoles y Membrillo, Ensalada de Pulpo a la Gallega, Paella de Mariscos \"Zafiro\", Lubina a la Sal con Pisto Mediterráneo, Solomillo Ibérico con Reducción de Oporto y Higos, Arroz Negro con Calamares y Alioli Suave, Bacalao Confitado con Patatas Panaderas, Pollo al Ajillo con Limón y Romero, Ravioles de Calabaza y Ricotta con Salsa de Salvia, Crema Catalana Tradicional, Tarta de Santiago con Helado de Turrón, Churros con Chocolate Fundido y Especias, Sangría \"Mesa Zafiro\" Premium, Cóctel \"El Zafiro Azul\"\n"
     ]
    }
   ],
   "source": [
    "response=chain.run(\"Mexican\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99175cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manav Darji\\AppData\\Local\\Temp\\ipykernel_23124\\3473216892.py:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  name_chain=LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurent for {cuisine} Food. Suggest a fency name for this i want only name not preamble and no postamble i want only one name\"\n",
    ")\n",
    "\n",
    "\n",
    "name_chain=LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
    "\n",
    "\n",
    "prompt_template_items=PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"\"\"Suggest some Menu item for {restaurant_name}. Return as a commma seperated Value not Preamble and postamble\"\"\"\n",
    ")\n",
    "\n",
    "food_item_chain=LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_item\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a3b412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manav Darji\\AppData\\Local\\Temp\\ipykernel_25380\\3314034507.py:9: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chains({\"cuisine\":\"Arabic\"})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': 'Almasia',\n",
       " 'menu_item': 'Whispering Root Soup, Moonpetal Dumplings, Sunstone Fritters, Glimmerwood Stew, Crystal Cavern Trout, Emberleaf Wrapped Roast, Sky Serpent Steak, Starfall Noodle Bowl, Cloud Blossom Tart, Glimmerdust Pudding, Elven Dew Nectar, Crimson Vine Wine, Twilight Berry Brew'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "\n",
    "chains=SequentialChain(chains=[name_chain, food_item_chain],\n",
    "                       input_variables=['cuisine'],\n",
    "                       output_variables=['restaurant_name', 'menu_item'])\n",
    "\n",
    "\n",
    "chains({\"cuisine\":\"Arabic\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758a297d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PM Modi was born on 17 September 1950. His age in 2025 will be 75 years.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_agent, load_tools\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "import dotenv\n",
    "import os\n",
    "import getpass\n",
    "dotenv.load_dotenv()\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass('GOOGLE_API_KEY') \n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\", temperature=.6)\n",
    "\n",
    "\n",
    "tools=load_tools(['wikipedia','llm-math'], llm=llm)\n",
    "\n",
    "agent=initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent.run(\"When Was PM Modi born? What is his age right now in 2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c538c711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrit\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "\n",
    "memory=ConversationBufferMemory()\n",
    "\n",
    "\n",
    "\n",
    "chain=LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "\n",
    "\n",
    "print(chain.run(\"Indian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad07c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Indian\n",
      "AI: Amrit\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
